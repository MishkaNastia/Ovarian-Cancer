{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Flux comparison\n",
    "\n",
    " In FIG. 4 , the authors compared subsystems by selecting the most de-regulated reactions across cell types (LG and HG). I think They optimized to max biomass each of the 7 models  (they generated 7 FBA solutions) and then they computed the average of each flux across cell lines of the same family.\n",
    "\n",
    "\n",
    "\n",
    " However, they selected one of the many solutions that respect max biomass growth. I suggest to:\n",
    "\n",
    "\n",
    "\n",
    " 1. Impose biomass at its upper bound for each model (LB = UB*0.90 to avoid solver numerical issues)\n",
    "\n",
    " 2. Run flux sampling with OPTGP (cobrapy) with thinning = 100 and 1k samples per cell line\n",
    "\n",
    " 3. DO not 'summarize' flux probability distributions with a simple average, but use more advanced methods. The objective here is to identify the most different reactions across the two cancer families. You could run non parametric statistical tests such as mann-whitney to check if two probability distributions are significantly different or not. You have 3 cells vs 2 cells (all pair combinations), so you could perform this test only on reactions belonging to core subsystems such as glycolysis, TCA cycle pentophosphate etc.. in order to redure the number of compared distribution per cell couple.\n",
    "\n",
    " 4. Once you identified the top-n most different probability distributions (reaction fluxes) across cells of different type, you could plot them with boxplots as the authors did\n",
    "\n",
    " 5. It might be interesting to check if we have 'less differences' in distributions of cells belonging to the same family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.sampling import sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cobra.io.json import load_json_model\n",
    "import numpy as np\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_json_model('./data/Recon3D.json')\n",
    "model.solver = 'gurobi'\n",
    "model.objective = 'BIOMASS_reaction'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Seperating reactions into pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsystem_dict = {}\n",
    "\n",
    "for r in model.reactions:\n",
    "    # get subsystem safely\n",
    "    s = (getattr(r, \"subsystem\", \"\") or \"\").strip()\n",
    "\n",
    "    # if it contains \"/\", keep only the first part\n",
    "    if \"/\" in s:\n",
    "        s = s.split(\"/\")[0].strip()   # take text before \"/\" and remove spaces\n",
    "\n",
    "    s = s.lower()\n",
    "\n",
    "    # skip empty subsystems\n",
    "    if not s:\n",
    "        continue\n",
    "\n",
    "    # add reaction to that subsystem list\n",
    "    subsystem_dict.setdefault(s, []).append(r.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED: Restricted keywords to only Glycolysis, TCA, and PPP\n",
    "category_keywords = {\n",
    "    \"Glycolysis\": [\n",
    "        \"glycolysis\", \"gluconeogenesis\"\n",
    "    ],\n",
    "    \n",
    "    \"TCA\": [\n",
    "        \"tca\", \"citric acid\", \"krebs\", \"tricarboxylic\"\n",
    "    ],\n",
    "    \n",
    "    \"Pentose Phosphate Pathway\": [\n",
    "        \"pentose phosphate\", \"ppp\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = {cat: [] for cat in category_keywords}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsystem_name, rxns in subsystem_dict.items():\n",
    "    name_lower = subsystem_name.lower()\n",
    "\n",
    "    for category, keywords in category_keywords.items():\n",
    "        # Check if any keyword exists in the subsystem name\n",
    "        if any(kw in name_lower for kw in keywords):\n",
    "            # Use set to avoid duplicate reaction IDs if they appear in multiple subsystem variants\n",
    "            selected[category].extend(rxns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, rxns in selected.items():\n",
    "    # Using set() here ensures unique IDs count\n",
    "    print(f\"{cat}: {len(set(rxns))} reactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check specific reactions for one of the groups (e.g., TCA)\n",
    "for rxn_id in list(set(selected[\"TCA\"]))[:5]: # printing first 5 as example\n",
    "    rxn = model.reactions.get_by_id(rxn_id)\n",
    "    print(rxn_id, \" â†’ \", rxn.subsystem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED: Final dictionary only contains the 3 requested pathways\n",
    "reactions_by_category = {\n",
    "    \"glycolysis\": list(set(selected[\"Glycolysis\"])),\n",
    "    \"tca\": list(set(selected[\"TCA\"])),\n",
    "    \"ppp\": list(set(selected[\"Pentose Phosphate Pathway\"]))\n",
    "}\n",
    "\n",
    "print(\"Categories created:\", reactions_by_category.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_grade = {\n",
    "    'ACH-000520': '59M',\n",
    "    'ACH-000542': 'HEYA8',\n",
    "    'ACH-000091': 'OV56'\n",
    "}\n",
    "high_grade = {\n",
    "    'ACH-000256': 'COV318',\n",
    "    'ACH-000713': 'CAOV3',\n",
    "    'ACH-000116': 'OAW28'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/flux_sampling_data_new\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sampling_for_group(group_dict, suffix):\n",
    "    for cl_id, cl_name in group_dict.items():\n",
    "        print(f\"\\n=== Processing {cl_name} ({cl_id}) â€” {suffix} ===\")\n",
    "\n",
    "        # Load FVA file\n",
    "        fva_path = f'./data/fva_rnaseq_{cl_id}_{suffix}.csv'\n",
    "        df_fva = pd.read_csv(fva_path, index_col=0)\n",
    "\n",
    "        # Clean invalid or missing bounds\n",
    "        df_fva[['minimum', 'maximum']] = df_fva[['minimum', 'maximum']].fillna(0.0)\n",
    "        invalid = df_fva['minimum'] > df_fva['maximum']\n",
    "        df_fva.loc[invalid, ['minimum', 'maximum']] = 0.0\n",
    "\n",
    "        #  Inject reaction bounds into model\n",
    "        for rxn_id, row in df_fva.iterrows():\n",
    "            model.reactions.get_by_id(rxn_id).bounds = (row['minimum'], row['maximum'])\n",
    "\n",
    "        # Check feasibility\n",
    "        sol = model.optimize()\n",
    "        print(f\"   Status: {sol.status}, Growth: {sol.objective_value}\")\n",
    "\n",
    "        #  Fix biomass at 90% of UB\n",
    "        UB = model.reactions.get_by_id('BIOMASS_reaction').upper_bound\n",
    "        model.reactions.get_by_id('BIOMASS_reaction').bounds = (0.9 * UB, UB)\n",
    "\n",
    "        # 7) Run flux sampling\n",
    "        print(\"   Running OPTGP sampling...\")\n",
    "        samples = sample(model, n=1000, method=\"optgp\", thinning=100, seed=42)\n",
    "\n",
    "        # 8) Save CSV\n",
    "        out_path = f\"./data/flux_sampling_data/flux_sampling_{suffix}_{cl_name}.csv\"\n",
    "        samples.to_csv(out_path)\n",
    "\n",
    "        print(f\"   Saved â†’ {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sampling_for_group(low_grade, \"LG\")\n",
    "run_sampling_for_group(high_grade, \"HG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Flux Distribution comparisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LG = {\n",
    "    \"59M\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_LG_59M.csv\", index_col=0),\n",
    "    \"HEYA8\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_LG_HEYA8.csv\", index_col=0),\n",
    "    \"OV56\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_LG_OV56.csv\", index_col=0)\n",
    "}\n",
    "\n",
    "HG = {\n",
    "    \"COV318\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_HG_COV318.csv\", index_col=0),\n",
    "    \"CAOV3\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_HG_CAOV3.csv\", index_col=0),\n",
    "    \"OAW28\": pd.read_csv(\"./data/flux_sampling_data/flux_sampling_HG_OAW28.csv\", index_col=0)\n",
    "}\"\"\"\n",
    "\n",
    "LG = {\n",
    "    \"59M\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_LG_59M.csv\", index_col=0),\n",
    "    \"HEYA8\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_LG_HEYA8.csv\", index_col=0),\n",
    "    \"OV56\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_LG_OV56.csv\", index_col=0)\n",
    "}\n",
    "\n",
    "HG = {\n",
    "    \"COV318\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_HG_COV318.csv\", index_col=0),\n",
    "    \"CAOV3\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_HG_CAOV3.csv\", index_col=0),\n",
    "    \"OAW28\": pd.read_csv(\"data/flux_sampling_data/flux_sampling_HG_OAW28.csv\", index_col=0)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Automated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "results = []\n",
    "\n",
    "# Iterate across all pathways\n",
    "for pathway, reactions in reactions_by_category.items():\n",
    "\n",
    "    for rxn in reactions:  # only reactions in this pathway\n",
    "\n",
    "        for lg_name, lg_df in LG.items():\n",
    "            for hg_name, hg_df in HG.items():\n",
    "\n",
    "                # extract distributions\n",
    "                if rxn not in lg_df.columns or rxn not in hg_df.columns:\n",
    "                    continue\n",
    "\n",
    "                lg_values = lg_df[rxn].dropna()\n",
    "                hg_values = hg_df[rxn].dropna()\n",
    "\n",
    "                # skip empty\n",
    "                if len(lg_values) == 0 or len(hg_values) == 0:\n",
    "                    continue\n",
    "\n",
    "                # compute means\n",
    "                mean_lg = lg_values.mean()\n",
    "                mean_hg = hg_values.mean()\n",
    "\n",
    "                # Fold Difference FD = |(mean_lg - mean_hg) / mean_hg|\n",
    "                if mean_hg == 0:\n",
    "                    FD = np.nan\n",
    "                else:\n",
    "                    FD = abs((mean_lg - mean_hg) / mean_hg)\n",
    "\n",
    "                # Mann-Whitney U test\n",
    "                stat, pval = mannwhitneyu(lg_values, hg_values, alternative=\"two-sided\")\n",
    "\n",
    "                results.append([\n",
    "                    pathway, rxn, lg_name, hg_name,\n",
    "                    stat, pval, mean_lg, mean_hg, FD\n",
    "                ])\n",
    "\n",
    "# Build DataFrame\n",
    "df_stats = pd.DataFrame(results, columns=[\n",
    "    \"pathway\", \"reaction\", \"LG\", \"HG\",\n",
    "    \"U_stat\", \"p_value\", \"mean_LG\", \"mean_HG\", \"fold_change\"\n",
    "])\n",
    "\n",
    "# Multiple testing correction\n",
    "df_stats[\"p_adjusted\"] = multipletests(df_stats[\"p_value\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# Keep significant results\n",
    "signif = df_stats[(df_stats[\"p_adjusted\"] < 0.01) & (df_stats[\"fold_change\"] > 0.90)].copy()\n",
    "\n",
    "top5_per_pathway = (\n",
    "    signif\n",
    "    .sort_values(by=\"fold_change\", ascending=True)\n",
    "    #  Filter out duplicates.\n",
    "    .drop_duplicates(subset=['reaction'], keep='first')\n",
    "    .groupby(\"pathway\")\n",
    "    .head(5)\n",
    "    \n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pathway_dict_for_cell(flux_df, top5_per_pathway):\n",
    "    \"\"\"\n",
    "    flux_df: flux sampling dataframe for ONE cell line (samples Ã— reactions)\n",
    "    top5_per_pathway: df with selected reactions (pathway + reaction)\n",
    "\n",
    "    returns:\n",
    "        dict[pathway] -> df (samples Ã— top reactions)\n",
    "    \"\"\"\n",
    "    pathway_dict = {}\n",
    "\n",
    "    for pathway in top5_per_pathway[\"pathway\"].unique():\n",
    "        # reactions selected for this pathway\n",
    "        rxns = top5_per_pathway.loc[\n",
    "            top5_per_pathway[\"pathway\"] == pathway, \"reaction\"\n",
    "        ].tolist()\n",
    "\n",
    "        # keep only reactions present in this cell line\n",
    "        rxns = [r for r in rxns if r in flux_df.columns]\n",
    "\n",
    "        if rxns:\n",
    "            pathway_dict[pathway] = flux_df[rxns].copy()\n",
    "\n",
    "    return pathway_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_pathway_dicts = {}\n",
    "for cell_name, flux_df in LG.items():\n",
    "    LG_pathway_dicts[cell_name] = build_pathway_dict_for_cell(flux_df, top5_per_pathway)\n",
    "\n",
    "HG_pathway_dicts = {}\n",
    "for cell_name, flux_df in HG.items():\n",
    "    HG_pathway_dicts[cell_name] = build_pathway_dict_for_cell(flux_df, top5_per_pathway)\n",
    "\n",
    "all_pathway_dicts = {**LG_pathway_dicts,**HG_pathway_dicts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pathway_dicts.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_cellline_pathway_dict(cellline_first_dict):\n",
    "    \"\"\"\n",
    "    input:  {cell_line -> {pathway -> df}}\n",
    "    output: {pathway  -> {cell_line -> df}}\n",
    "    \"\"\"\n",
    "    pathway_first = {}\n",
    "\n",
    "    for cell_line, pw_dict in cellline_first_dict.items():\n",
    "        for pathway, df in pw_dict.items():\n",
    "            if pathway not in pathway_first:\n",
    "                pathway_first[pathway] = {}\n",
    "            pathway_first[pathway][cell_line] = df\n",
    "\n",
    "    return pathway_first\n",
    "\n",
    "\n",
    "pathway_dicts = invert_cellline_pathway_dict(all_pathway_dicts)\n",
    "pathway_dicts['glycolysis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Access the inner dictionary using the outer key ('59M')\n",
    "LG_pathway_dicts['OV56']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_LG_names =list(LG_pathway_dicts.keys())\n",
    "list_LG_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list_LG_names:\n",
    "    subkeys = LG_pathway_dicts[key].keys()\n",
    "    list_pathways= list(subkeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pathways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_pathway_dicts[\"59M\"]['fatty_acid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_pathway_dicts[\"59M\"]['lipid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = LG_pathway_dicts[\"59M\"]['fatty_acid'].melt(var_name=\"reaction\", value_name=\"flux\")\n",
    "df_long\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_flux_distributions_by_pathway(pathway, cell_dict):\n",
    "    \"\"\"\n",
    "    pathway: name of the pathway (string), used for the title\n",
    "    cell_dict: { cell_line -> df(samples Ã— reactions) } for this pathway\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------- Build combined long dataframe -----------\n",
    "    long_frames = []\n",
    "\n",
    "    for cell_line, df in cell_dict.items():\n",
    "        df_long = df.melt(\n",
    "            var_name=\"reaction\",\n",
    "            value_name=\"flux\"\n",
    "        )\n",
    "        df_long[\"cell_line\"] = cell_line\n",
    "        long_frames.append(df_long)\n",
    "\n",
    "    df_all = pd.concat(long_frames, ignore_index=True)\n",
    "\n",
    "    # ----------- Get list of reactions --------------------\n",
    "    reactions = df_all[\"reaction\"].unique()\n",
    "    n = len(reactions)\n",
    "\n",
    "    # ----------- Create subplots --------------------------\n",
    "    fig, axes = plt.subplots(\n",
    "        1, n,\n",
    "        figsize=(5 * n, 4),\n",
    "        sharey=False\n",
    "    )\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # ----------- Plot each reaction -----------------------\n",
    "    for ax, rxn in zip(axes, reactions):\n",
    "        sub = df_all[df_all[\"reaction\"] == rxn]\n",
    "\n",
    "        # ðŸ”¹ variance per cell line for this reaction\n",
    "        var_per_cell = sub.groupby(\"cell_line\")[\"flux\"].var()\n",
    "\n",
    "        print(f\"\\n=== Reaction: {rxn} (pathway: {pathway}) ===\")\n",
    "        print(var_per_cell)\n",
    "\n",
    "        # optional: highlight almost-constant ones\n",
    "        very_small = var_per_cell[var_per_cell < 1e-10]\n",
    "        if len(very_small) > 0:\n",
    "            print(\"  -> Nearly constant in:\", list(very_small.index))\n",
    "\n",
    "        sns.kdeplot(\n",
    "            data=sub,\n",
    "            x=\"flux\",\n",
    "            hue=\"cell_line\",\n",
    "            fill=True,\n",
    "            common_norm=False,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_title(rxn)\n",
    "        ax.set_xlabel(\"Flux\")\n",
    "        ax.set_ylabel(\"Density\")\n",
    "\n",
    "    plt.suptitle(f\"Flux Distributions â€” {pathway}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathway, cell_dict in pathway_dicts.items():\n",
    "    plot_flux_distributions_by_pathway(pathway, cell_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_long, x=\"flux\", hue=\"cell_line\", kind=\"kde\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
